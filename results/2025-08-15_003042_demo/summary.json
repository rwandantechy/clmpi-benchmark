{
  "run_name": "benchmark_run",
  "timestamp": "2025-08-15_003042",
  "label": "demo",
  "seed": 42,
  "hardware_info": {
    "cpu_model": "i386",
    "cpu_cores": "12",
    "memory_gb": "16.0",
    "os": "Darwin 24.5.0",
    "python_version": "3.12.4"
  },
  "config_used": {
    "model_config": "{'evaluation_weights': {'accuracy': 0.25, 'contextual_understanding': 0.2, 'coherence': 0.2, 'fluency': 0.2, 'performance_efficiency': 0.15}, 'prompt_sets': {'accuracy': ['classification_tasks.json', 'reasoning_tasks.json'], 'contextual_understanding': ['contextual_tasks.json'], 'coherence': ['contextual_tasks.json'], 'fluency': ['classification_tasks.json'], 'performance_efficiency': ['classification_tasks.json']}, 'models': {'phi3:mini': {'ollama_name': 'phi3:mini', 'max_tokens': 1000, 'temperature': 0.1, 'timeout_seconds': 30}, 'mistral': {'ollama_name': 'mistral', 'max_tokens': 1000, 'temperature': 0.1, 'timeout_seconds': 45}, 'llama2:7b-chat': {'ollama_name': 'llama2:7b-chat', 'max_tokens': 1000, 'temperature': 0.1, 'timeout_seconds': 60}, 'gemma:2b': {'ollama_name': 'gemma:2b', 'max_tokens': 1000, 'temperature': 0.1, 'timeout_seconds': 20}}, 'evaluation': {'samples_per_task': 5, 'random_seed': 42, 'save_raw_responses': True, 'generate_visualizations': True}}",
    "evaluation_weights": {
      "accuracy": 0.25,
      "contextual_understanding": 0.2,
      "coherence": 0.2,
      "fluency": 0.2,
      "performance_efficiency": 0.15
    }
  },
  "results": [
    {
      "model_name": "phi3:mini",
      "evaluation_timestamp": "2025-08-15T00:30:42.390471",
      "responses": {
        "accuracy": [
          "Mock response for: Determine the genre of this excerpt: 'Amid the ten...",
          "Mock response for: Analyze the sentiment of the following text: 'I ab...",
          "Mock response for: What is the main topic of this text: 'The stock ma...",
          "Mock response for: Why do leaves change color in the fall? Explain th...",
          "Mock response for: If all roses are flowers, and some flowers are red...",
          "Mock response for: Complete the analogy: Book is to reading as fork i..."
        ],
        "contextual_understanding": [
          "Mock contextual response for: From our conversation, what were the specific step...",
          "Mock contextual response for: According to the summary, what are the main factor...",
          "Mock contextual response for: Based on our conversation, what would be three spe..."
        ]
      },
      "component_scores": {
        "accuracy": 0.0,
        "contextual_understanding": 3.0,
        "coherence": 4.0,
        "fluency": 3.5,
        "performance_efficiency": 0.037037037037037035
      },
      "performance_metrics": {
        "total_time_seconds": 18.0,
        "total_memory_mb": 900.0,
        "efficiency_score": 0.037037037037037035
      },
      "clmpi_score_01": 0.4255555555555556,
      "clmpi_score_100": 42.55555555555556
    }
  ]
}